
因为机子原因，折腾了好久IDE，现在已经在大脑里把整个程序构建好了，开始转移到电脑上。


――2013.9.19 16：33


刚把K-Means算法跟使用MapReduce编程模型的思路看完，因为数学专业不学这个，没有接触过这些，所以还是有必要写一些随笔，防止以后忘记。



首先把K-Means算法基本思路复习一下，这个方法还是挺简单的，以前做数模用matlab跟SPSS用过，不过那时候不知道怎么实现的：

1.人为确定K的初始值，也就是需要把N个样本分为多少类；

2.生成K个点，令其分别为K个类的“中心”，作为中心的初始值进入下面的计算；（随笔：这里除了随机法，应该也可以稍微有AI一点，比如求每个记录向量的2-范数，然后把所有范数等个数间距取K个出来，那K个就可以作为中心的初始值。暂时觉得这样会好一些，maybe可以证明）

3.计算每个样本point到所有K个类的距离，选择距离它最近的那个类，作为其新的所属类。（随笔：这个距离应该不仅仅可以是Euclid距离，应该可以根据不同的需要选择Jacobi距离、Hamilton距离之类的，可能只要是度量空间里定义出来的距离都可以用）

4.对每个类，重新计算其中心。（随笔：在论文里看到weighted average,觉得是不是可以根据不同样本point的重要性来对不同点设置权重，而不仅仅只是单纯取所有分量的平均。实际情况中可能会有这样的情况发生，某些样本点确实要重要一些）

5.计算中心的偏移程度，如果超过了某个阈值，就返回步骤3继续算；否则算法结束。（随笔：实际中这个阈值应该没必要设得太小，不然既浪费时间效果又不好）



直接用的时间复杂度是N*K*r*H，r是迭代次数，H是求一次距离的复杂度。首先迭代次数跟算法本身有关，算法确定之后r对复杂度起的作用比较小。而N*K*H表示每次迭代需要计算距离的总次数，这个在N*K比较大的时候是吃不消的。
也就是说这个地方可以多线程一下。
然后是把MapReduce套用在K-Means算法上，这样就并行化了。



MapReduce让大量的数据进行分片(split)，每个片都分配到一个核的处理器，而这些处理器都可以访问同一个file，里面存放着每次迭代结束后都会更新的K个类的中心。MapReduce主要是map函数和reduce函数发挥作用：

map函数：这个函数其实就是一个映射，作用是求每个样本point到K个类的中心的最小距离，然后把它们分别分配到各自的新分类中。
伪代码的话是这样：
void map(int key_number,Point point)
{
    min_distance=inf;
    枚举k个类的中心
    {
        如果该中心与当前点的距离比min_distance短，就更新min_distance，并记录其所属的新类;
    }
    整理数据，然后把数据传给reduce函数
}


然后是reduce函数：这个函数就是用来求各个类的新中心的，每轮迭代结束后运行。
伪代码：
void reduce(int key_number,Pointsets points)
{
    num=0;
    while(存在类的中心没有被计算)
    {
        num+=该类中样本点的个数;
        对向量的每个维度求平均值，确定新的中心;
    }
    更新文件;
}



――2013.9.19 09：13